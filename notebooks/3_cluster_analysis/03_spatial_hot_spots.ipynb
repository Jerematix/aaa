{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Spatial Hot Spots\n",
    "\n",
    "In the following, an attempt is made to classify the cab trips into clusters of start and end points using the processed dataset, with spatial hotspots can be identified.\n",
    "\n",
    "The approach of soft clustering with GMM is used. The dataset is analyzed on the basis of the start and end points, since these can be different due to empty trips, which are not included in the dataset.\n",
    "\n",
    "Only the sampled dataset with about 1% of the data is used because a calculation of the full dataset was not completed after more than 96 hours."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports and preparatory calculations\n",
    "In the following, the necessary libraries are imported and the data set is loaded and displayed superficially.\n",
    "\n",
    "Furthermore, preparatory calculations are performed to extracte the longitude and latitude ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T20:25:27.703577Z",
     "start_time": "2023-08-10T20:25:27.365186Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "#trips_df = pd.read_parquet('../../data/rides/Taxi_Trips_Sampled_Cleaned.parquet') #Sampled\n",
    "trips_df = pd.read_parquet('../../data/rides/Taxi_Trips_Cleaned.parquet') #NonSampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T20:25:34.717545Z",
     "start_time": "2023-08-10T20:25:27.703917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-10T20:25:34.733459Z",
     "start_time": "2023-08-10T20:25:34.724340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17065882 entries, 0 to 17065881\n",
      "Data columns (total 44 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   taxi_id                 int64         \n",
      " 1   trip_start_timestamp    datetime64[ns]\n",
      " 2   trip_end_timestamp      datetime64[ns]\n",
      " 3   trip_seconds            float64       \n",
      " 4   trip_miles              float64       \n",
      " 5   pickup_census_tract     int64         \n",
      " 6   dropoff_census_tract    int64         \n",
      " 7   pickup_community_area   int64         \n",
      " 8   dropoff_community_area  int64         \n",
      " 9   fare                    float64       \n",
      " 10  tips                    float64       \n",
      " 11  tolls                   float64       \n",
      " 12  Extras                  float64       \n",
      " 13  trip_total              float64       \n",
      " 14  payment_type            object        \n",
      " 15  Company                 object        \n",
      " 16  hour_start              int32         \n",
      " 17  4_hour_block_start      int32         \n",
      " 18  day_start               int32         \n",
      " 19  dayofweek_start         int32         \n",
      " 20  week_start              UInt32        \n",
      " 21  month_start             int32         \n",
      " 22  hour_end                int32         \n",
      " 23  4_hour_block_end        int32         \n",
      " 24  day_end                 int32         \n",
      " 25  dayofweek_end           int32         \n",
      " 26  week_end                UInt32        \n",
      " 27  month_end               int32         \n",
      " 28  is_weekday              bool          \n",
      " 29  h3_05_pickup            object        \n",
      " 30  h3_05_dropoff           object        \n",
      " 31  h3_06_pickup            object        \n",
      " 32  h3_06_dropoff           object        \n",
      " 33  h3_07_pickup            object        \n",
      " 34  h3_07_dropoff           object        \n",
      " 35  h3_08_pickup            object        \n",
      " 36  h3_08_dropoff           object        \n",
      " 37  h3_09_pickup            object        \n",
      " 38  h3_09_dropoff           object        \n",
      " 39  pickup_centroid         object        \n",
      " 40  dropoff_centroid        object        \n",
      " 41  datetime                datetime64[ns]\n",
      " 42  temp                    float64       \n",
      " 43  precip                  int64         \n",
      "dtypes: UInt32(2), bool(1), datetime64[ns](3), float64(8), int32(10), int64(6), object(14)\n",
      "memory usage: 4.8+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   taxi_id trip_start_timestamp  trip_end_timestamp  trip_seconds  trip_miles  \\\n0        1  2015-01-01 00:00:00 2015-01-01 00:00:00         420.0         1.0   \n1        2  2015-01-01 00:30:00 2015-01-01 00:30:00         480.0         1.9   \n2        3  2015-01-01 00:30:00 2015-01-01 00:45:00         300.0         1.0   \n3        4  2015-01-01 00:30:00 2015-01-01 00:30:00         180.0         0.7   \n4        5  2015-01-01 00:30:00 2015-01-01 00:45:00         600.0         2.2   \n\n   pickup_census_tract  dropoff_census_tract  pickup_community_area  \\\n0          17031081500           17031320100                      8   \n1          17031081700           17031832600                      8   \n2          17031081700           17031842200                      8   \n3          17031062800           17031062900                      6   \n4          17031051300           17031071200                      5   \n\n   dropoff_community_area  fare  ...    h3_07_dropoff     h3_08_pickup  \\\n0                      32  6.05  ...  872664c1effffff  882664c1e1fffff   \n1                       7  7.65  ...  872664c13ffffff  882664c1e7fffff   \n2                       8  5.25  ...  872664c13ffffff  882664c1e7fffff   \n3                       6  4.65  ...  872664c16ffffff  882664c129fffff   \n4                       7  8.25  ...  872664c13ffffff  882664c12dfffff   \n\n     h3_08_dropoff     h3_09_pickup    h3_09_dropoff  \\\n0  882664c1e3fffff  892664c1e0fffff  892664c1e2fffff   \n1  882664c135fffff  892664c1e73ffff  892664c13cfffff   \n2  882664c137fffff  892664c1e73ffff  892664c1377ffff   \n3  882664c163fffff  892664c1293ffff  892664c162fffff   \n4  882664c107fffff  892664c12dbffff  892664c106fffff   \n\n                      pickup_centroid                    dropoff_centroid  \\\n0  POINT (-87.626214906 41.892507781)  POINT (-87.620992913 41.884987192)   \n1   POINT (-87.63186395 41.892042136)  POINT (-87.654007029 41.914747305)   \n2   POINT (-87.63186395 41.892042136)  POINT (-87.649907226 41.904935302)   \n3  POINT (-87.661265218 41.936159071)  POINT (-87.656411531 41.936237179)   \n4  POINT (-87.675821928 41.935983574)  POINT (-87.646210977 41.921854911)   \n\n    datetime    temp  precip  \n0 2015-01-01 -7.0115       0  \n1 2015-01-01 -7.0115       0  \n2 2015-01-01 -7.0115       0  \n3 2015-01-01 -7.0115       0  \n4 2015-01-01 -7.0115       0  \n\n[5 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>taxi_id</th>\n      <th>trip_start_timestamp</th>\n      <th>trip_end_timestamp</th>\n      <th>trip_seconds</th>\n      <th>trip_miles</th>\n      <th>pickup_census_tract</th>\n      <th>dropoff_census_tract</th>\n      <th>pickup_community_area</th>\n      <th>dropoff_community_area</th>\n      <th>fare</th>\n      <th>...</th>\n      <th>h3_07_dropoff</th>\n      <th>h3_08_pickup</th>\n      <th>h3_08_dropoff</th>\n      <th>h3_09_pickup</th>\n      <th>h3_09_dropoff</th>\n      <th>pickup_centroid</th>\n      <th>dropoff_centroid</th>\n      <th>datetime</th>\n      <th>temp</th>\n      <th>precip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2015-01-01 00:00:00</td>\n      <td>2015-01-01 00:00:00</td>\n      <td>420.0</td>\n      <td>1.0</td>\n      <td>17031081500</td>\n      <td>17031320100</td>\n      <td>8</td>\n      <td>32</td>\n      <td>6.05</td>\n      <td>...</td>\n      <td>872664c1effffff</td>\n      <td>882664c1e1fffff</td>\n      <td>882664c1e3fffff</td>\n      <td>892664c1e0fffff</td>\n      <td>892664c1e2fffff</td>\n      <td>POINT (-87.626214906 41.892507781)</td>\n      <td>POINT (-87.620992913 41.884987192)</td>\n      <td>2015-01-01</td>\n      <td>-7.0115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>480.0</td>\n      <td>1.9</td>\n      <td>17031081700</td>\n      <td>17031832600</td>\n      <td>8</td>\n      <td>7</td>\n      <td>7.65</td>\n      <td>...</td>\n      <td>872664c13ffffff</td>\n      <td>882664c1e7fffff</td>\n      <td>882664c135fffff</td>\n      <td>892664c1e73ffff</td>\n      <td>892664c13cfffff</td>\n      <td>POINT (-87.63186395 41.892042136)</td>\n      <td>POINT (-87.654007029 41.914747305)</td>\n      <td>2015-01-01</td>\n      <td>-7.0115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>2015-01-01 00:45:00</td>\n      <td>300.0</td>\n      <td>1.0</td>\n      <td>17031081700</td>\n      <td>17031842200</td>\n      <td>8</td>\n      <td>8</td>\n      <td>5.25</td>\n      <td>...</td>\n      <td>872664c13ffffff</td>\n      <td>882664c1e7fffff</td>\n      <td>882664c137fffff</td>\n      <td>892664c1e73ffff</td>\n      <td>892664c1377ffff</td>\n      <td>POINT (-87.63186395 41.892042136)</td>\n      <td>POINT (-87.649907226 41.904935302)</td>\n      <td>2015-01-01</td>\n      <td>-7.0115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>180.0</td>\n      <td>0.7</td>\n      <td>17031062800</td>\n      <td>17031062900</td>\n      <td>6</td>\n      <td>6</td>\n      <td>4.65</td>\n      <td>...</td>\n      <td>872664c16ffffff</td>\n      <td>882664c129fffff</td>\n      <td>882664c163fffff</td>\n      <td>892664c1293ffff</td>\n      <td>892664c162fffff</td>\n      <td>POINT (-87.661265218 41.936159071)</td>\n      <td>POINT (-87.656411531 41.936237179)</td>\n      <td>2015-01-01</td>\n      <td>-7.0115</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2015-01-01 00:30:00</td>\n      <td>2015-01-01 00:45:00</td>\n      <td>600.0</td>\n      <td>2.2</td>\n      <td>17031051300</td>\n      <td>17031071200</td>\n      <td>5</td>\n      <td>7</td>\n      <td>8.25</td>\n      <td>...</td>\n      <td>872664c13ffffff</td>\n      <td>882664c12dfffff</td>\n      <td>882664c107fffff</td>\n      <td>892664c12dbffff</td>\n      <td>892664c106fffff</td>\n      <td>POINT (-87.675821928 41.935983574)</td>\n      <td>POINT (-87.646210977 41.921854911)</td>\n      <td>2015-01-01</td>\n      <td>-7.0115</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 44 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General presentation of the dataframe\n",
    "trips_df.info()\n",
    "trips_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extract the longitude and latitude\n",
    "First, we extract the longitude and latitude from the data to cluster based on them.  \n",
    "This is done once for the pickup data and once for the dropoff data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Extract the longitude and latitude\n",
    "def extract_coordinates(point):\n",
    "    coords = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", point)\n",
    "    return [float(coord) for coord in coords]\n",
    "\n",
    "trips_df['pickup_point'] = trips_df['pickup_centroid'].apply(extract_coordinates)\n",
    "trips_df['dropoff_point'] = trips_df['dropoff_centroid'].apply(extract_coordinates)\n",
    "\n",
    "pickup_coordinates = np.vstack(trips_df['pickup_point'].values)\n",
    "dropoff_coordinates = np.vstack(trips_df['dropoff_point'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-10T20:25:34.805525Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Determination of the hyperparameters\n",
    "\n",
    "We would now like to set the hyperparameters for our GMM. This is first the number of clusters we want to find. Furthermore, the optimal bandwidth for the kernel density estimation has to be found. \n",
    "\n",
    "#### Calculation of the optimal number of clusters with the elbow method\n",
    "First, we compute the inertia for up to 10 clusters and then use the visualization to select the optimal number of clusters at the point where an elbow can be seen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_components = np.arange(1, 10)\n",
    "\n",
    "# Model for pickup\n",
    "models_pickup = [GaussianMixture(n, covariance_type='full', random_state=0).fit(pickup_coordinates)\n",
    "                 for n in n_components]\n",
    "# Model for dropoff\n",
    "models_dropoff = [GaussianMixture(n, covariance_type='full', random_state=0).fit(dropoff_coordinates)\n",
    "                  for n in n_components]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-10T20:26:39.787580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot pickup\n",
    "plt.plot(n_components, [-m.score(pickup_coordinates) for m in models_pickup], color='blue', label='Pickup', marker='o')\n",
    "\n",
    "# Plot dropoff\n",
    "plt.plot(n_components, [-m.score(dropoff_coordinates) for m in models_dropoff], color='red', label='Dropoff', marker='o')\n",
    "\n",
    "# Labeling and legend\n",
    "plt.title('Elbow method for determining the optimal number of clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can be seen that the inertia does not decrease noticeably after 4 to 5 clusters. Therefore, 4 clusters are now calculated in K Means in order to further anlayze them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculation of the optimal bandwith for KDE\n",
    "Define a function, calculate_best_bandwidth, which determines the optimal bandwidth value for kernel density estimation by using GridSearchCV.Then calculates the best bandwidth values for both pickup and dropoff coordinates of trips."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_best_bandwidth(coordinates, bandwidths_range=(-1, 1, 10), cv=5, n_jobs=-1):\n",
    "    # Calculate the optimal bandwidth\n",
    "    bandwidths = 10 ** np.linspace(*bandwidths_range)\n",
    "\n",
    "    # Generate a KernelDensity object\n",
    "    kde = KernelDensity()\n",
    "\n",
    "    # Use GridSearchCV to find the best bandwidth\n",
    "    # Set n_jobs=-1 to use all available cores\n",
    "    grid = GridSearchCV(kde, {'bandwidth': bandwidths}, cv=cv, n_jobs=n_jobs)  # Cross-validation\n",
    "    grid.fit(coordinates)\n",
    "\n",
    "    # Best bandwidth\n",
    "    best_bandwidth = grid.best_params_['bandwidth']\n",
    "\n",
    "    return best_bandwidth\n",
    "\n",
    "# Calculate best bandwidth for pickup location\n",
    "best_bandwidth_pickup = calculate_best_bandwidth(pickup_coordinates)\n",
    "print(\"Best Bandwidth Pickup: \", best_bandwidth_pickup)\n",
    "\n",
    "# Calculate best bandwidth for dropoff location\n",
    "best_bandwidth_dropoff = calculate_best_bandwidth(dropoff_coordinates)\n",
    "print(\"Best Bandwidth Dropoff: \", best_bandwidth_dropoff)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a spatial kernel density estimate\n",
    "Now we establishe a spatial kernel density estimation for both pickup and dropoff coordinates using a Gaussian kernel. Then, computes the density estimates for the data points of these coordinates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a spatial kernel density estimation\n",
    "kde_pickup = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth_pickup).fit(pickup_coordinates)\n",
    "kde_dropoff = KernelDensity(kernel='gaussian', bandwidth=best_bandwidth_dropoff).fit(dropoff_coordinates)\n",
    "\n",
    "# Calculate the density estimation for the data points\n",
    "pickup_density = np.exp(kde_pickup.score_samples(pickup_coordinates))\n",
    "dropoff_density = np.exp(kde_dropoff.score_samples(dropoff_coordinates))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Mixture Model\n",
    "\n",
    "Now we create the GMM based on the KDE and calculate the spatial hotspot centers and their sizes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Application of Gaussian mixed models to density estimation\n",
    "gmm_pickup = GaussianMixture(n_components=4).fit(pickup_coordinates, pickup_density)\n",
    "gmm_dropoff = GaussianMixture(n_components=4).fit(dropoff_coordinates, dropoff_density)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cache the results in variables\n",
    "pickup_covariances = gmm_pickup.covariances_\n",
    "dropoff_covariances = gmm_dropoff.covariances_\n",
    "pickup_centers = gmm_pickup.means_\n",
    "dropoff_centers = gmm_dropoff.means_\n",
    "\n",
    "# Display the location (means) and size (variances) of the identified hotspots\n",
    "print(\"Hotspot Centers (Pickup):\", gmm_pickup.means_)\n",
    "print(\"Hotspot Sizes (Pickup):\", gmm_pickup.covariances_)\n",
    "print(\"Hotspot Centers (Dropoff):\", gmm_dropoff.means_)\n",
    "print(\"Hotspot Sizes (Dropoff):\", gmm_dropoff.covariances_)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualsisierung\n",
    "Now we visualize the identified hotspots for both pickup and dropoff locations on a map centered around Chicago. Blue markers indicate pickup centers, while red markers represent dropoff centers. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a map centered on Chicago\n",
    "m = folium.Map(location=[41.8781, -87.6298], zoom_start=11, control_scale=False)\n",
    "\n",
    "# Fetching the centers and covariances\n",
    "pickup_centers = gmm_pickup.means_\n",
    "dropoff_centers = gmm_dropoff.means_\n",
    "\n",
    "# Adding markers for pickup centers\n",
    "for center in pickup_centers:\n",
    "    folium.Marker(location=[center[1], center[0]],\n",
    "                  icon=folium.Icon(color='blue'),\n",
    "                  popup='Pickup Center').add_to(m)\n",
    "\n",
    "# Adding markers for dropoff centers\n",
    "for center in dropoff_centers:\n",
    "    folium.Marker(location=[center[1], center[0]],\n",
    "                  icon=folium.Icon(color='red'),\n",
    "                  popup='Dropoff Center').add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
